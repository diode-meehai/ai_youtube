{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Jupyter notebook from myai.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbimporter\n",
    "import myai as ai\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor:\n",
    "    adj = []\n",
    "    total_id = 0\n",
    "    e = 2.718281828459045\n",
    "    n_samples = 'wait for assigned'\n",
    "    \n",
    "    def __init__(self, data, represent, torch_type='sample'):\n",
    "        _dict = {}\n",
    "        _dict['id'] = tensor.total_id\n",
    "        _dict['data'] = data\n",
    "        _dict['represent'] = represent\n",
    "        _dict['torch_type'] = torch_type\n",
    "        _dict['created_from'] = 'assigned'\n",
    "        _dict['send_to'] = []\n",
    "        _dict['diff'] = []\n",
    "        _dict['family'] = set()\n",
    "        _dict['storage_chain_rule'] = None\n",
    "        if torch_type == 'sample' and tensor.n_samples == 'wait for assigned':\n",
    "            tensor.n_samples = represent.shape[0]\n",
    "        tensor.adj.append(_dict)\n",
    "        self.id = tensor.total_id\n",
    "        tensor.total_id += 1\n",
    "        self.data = data\n",
    "        \n",
    "    def update_so(self, self_id, other_id, new_var_id, operation):\n",
    "        tensor.adj[self_id]['send_to'].append(new_var_id)\n",
    "        tensor.adj[other_id]['send_to'].append(new_var_id)\n",
    "        tensor.adj[new_var_id]['created_from'] = operation\n",
    "        \n",
    "        self_set = tensor.adj[self_id]['family']\n",
    "        other_set = tensor.adj[other_id]['family']\n",
    "        tensor.adj[new_var_id]['family'].add(self_id)\n",
    "        tensor.adj[new_var_id]['family'].add(other_id)\n",
    "        tensor.adj[new_var_id]['family'] = tensor.adj[new_var_id]['family'] | self_set | other_set\n",
    "        \n",
    "    def update_s(self, self_id, new_var_id, operation):\n",
    "        tensor.adj[self_id]['send_to'].append(new_var_id)\n",
    "        tensor.adj[new_var_id]['created_from'] = operation\n",
    "        \n",
    "        self_set = tensor.adj[self_id]['family']\n",
    "        tensor.adj[new_var_id]['family'].add(self_id)\n",
    "        tensor.adj[new_var_id]['family'] = tensor.adj[new_var_id]['family'] | self_set\n",
    "        \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, tensor):\n",
    "            represent = tensor.adj[self.id]['represent'] + tensor.adj[other.id]['represent']\n",
    "            new_var = tensor(self.data + other.data, represent)\n",
    "            operation = ('+', self.id, other.id)\n",
    "            self.update_so(self.id, other.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(np.ones([tensor.n_samples, 1]))\n",
    "            tensor.adj[other.id]['diff'].append(np.ones([tensor.n_samples, 1]))\n",
    "        else:\n",
    "            represent = tensor.adj[self.id]['represent'] + other\n",
    "            new_var = tensor(self.data + other, represent)\n",
    "            operation = ('+', self.id, str(other))\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        if not isinstance(other, tensor):\n",
    "            represent = other + tensor.adj[self.id]['represent']\n",
    "            new_var = tensor(other + self.data, represent)\n",
    "            operation = ('+', str(other), self.id)\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, tensor):\n",
    "            represent = tensor.adj[self.id]['represent'] - tensor.adj[other.id]['represent']\n",
    "            new_var = tensor(self.data - other.data, represent)\n",
    "            operation = ('-', self.id, other.id)\n",
    "            self.update_so(self.id, other.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(np.ones([tensor.n_samples, 1]))\n",
    "            tensor.adj[other.id]['diff'].append(-np.ones([tensor.n_samples, 1]))\n",
    "        else:\n",
    "            represent = tensor.adj[self.id]['represent'] - other\n",
    "            new_var = tensor(self.data - other, represent)\n",
    "            operation = ('-', self.id, str(other))\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def __rsub__(self, other):\n",
    "        if not isinstance(other, tensor):\n",
    "            represent = other - tensor.adj[self.id]['represent']\n",
    "            new_var = tensor(other - self.data, represent)\n",
    "            operation = ('-', str(other), self.id)\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(-np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, tensor):\n",
    "            represent = tensor.adj[self.id]['represent']*tensor.adj[other.id]['represent']\n",
    "            new_var = tensor(self.data * other.data, represent)\n",
    "            operation = ('*', self.id, other.id)\n",
    "            self.update_so(self.id, other.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(tensor.adj[other.id]['represent'])\n",
    "            tensor.adj[other.id]['diff'].append(tensor.adj[self.id]['represent'])\n",
    "        else:\n",
    "            represent = tensor.adj[self.id]['represent']*other\n",
    "            new_var = tensor(self.data * other, represent)\n",
    "            operation = ('*', self.id, str(other))\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(other * np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        if not isinstance(other, tensor):\n",
    "            represent = other*tensor.adj[self.id]['represent']\n",
    "            new_var = tensor(other * self.data, represent)\n",
    "            operation = ('*', str(other), self.id)\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(other * np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        if isinstance(other, tensor):\n",
    "            represent = tensor.adj[self.id]['represent']/tensor.adj[other.id]['represent']\n",
    "            new_var = tensor(self.data / other.data, represent)\n",
    "            operation = ('/', self.id, other.id)\n",
    "            self.update_so(self.id, other.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(1/tensor.adj[other.id]['represent'])\n",
    "            tensor.adj[other.id]['diff'].append(-tensor.adj[self.id]['represent']/tensor.adj[other.id]['represent']**2)\n",
    "        else:\n",
    "            represent = tensor.adj[self.id]['represent']/other\n",
    "            new_var = tensor(self.data / other, represent)\n",
    "            operation = ('/', self.id, str(other))\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append((1/other) * np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def __rtruediv__(self, other):\n",
    "        if not isinstance(other, tensor):\n",
    "            represent = other / tensor.adj[self.id]['represent']\n",
    "            new_var = tensor(other / self.data, represent)\n",
    "            operation = ('/', str(other), self.id)\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            tensor.adj[self.id]['diff'].append(-other/tensor.adj[self.id]['represent']**2)\n",
    "        return new_var\n",
    "        \n",
    "    def __pow__(self, other):\n",
    "        if isinstance(other, tensor):\n",
    "            represent = tensor.adj[self.id]['represent'] ** tensor.adj[other.id]['represent']\n",
    "            new_var = tensor(self.data ** other.data, represent)\n",
    "            operation = ('**', self.id, other.id)\n",
    "            self.update_so(self.id, other.id, new_var.id, operation)\n",
    "            self_rep = tensor.adj[self.id]['represent']\n",
    "            other_rep = tensor.adj[other.id]['represent']\n",
    "            tensor.adj[self.id]['diff'].append(other_rep*self_rep**(other_rep-1))\n",
    "            tensor.adj[other.id]['diff'].append((self_rep**other_rep)*np.log(self_rep))\n",
    "        else:\n",
    "            represent = tensor.adj[self.id]['represent'] ** other\n",
    "            new_var = tensor(self.data ** other, represent)\n",
    "            operation = ('**', self.id, str(other))\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            self_rep = tensor.adj[self.id]['represent']\n",
    "            tensor.adj[self.id]['diff'].append(other*self_rep**(other-1))\n",
    "        return new_var\n",
    "    \n",
    "    def __rpow__(self, other):\n",
    "        if not isinstance(other, tensor):\n",
    "            represent = other ** tensor.adj[self.id]['represent']\n",
    "            new_var = tensor(other ** self.data, represent)\n",
    "            operation = ('**', str(other), self.id)\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            self_rep = tensor.adj[self.id]['represent']\n",
    "            tensor.adj[self.id]['diff'].append((other**self_rep)*np.log(other))\n",
    "        return new_var\n",
    "    \n",
    "    def __neg__(self):\n",
    "        represent = -tensor.adj[self.id]['represent']\n",
    "        new_var = tensor(-self.data, represent)\n",
    "        operation = ('-1*', self.id)\n",
    "        self.update_s(self.id, new_var.id, operation)\n",
    "        tensor.adj[self.id]['diff'].append(-np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def __abs__(self):\n",
    "        represent = np.abs(tensor.adj[self.id]['represent'])\n",
    "        new_var = tensor(abs(self.data), represent)\n",
    "        operation = ('abs', self.id)\n",
    "        self.update_s(self.id, new_var.id, operation)\n",
    "        diff_abs = (tensor.adj[self.id]['represent'] > 0) -1*(tensor.adj[self.id]['represent'] < 0)\n",
    "        tensor.adj[self.id]['diff'].append(diff_abs * np.ones([tensor.n_samples, 1]))\n",
    "        return new_var\n",
    "    \n",
    "    def log(self):\n",
    "        represent = np.log(tensor.adj[self.id]['represent'])\n",
    "        new_var = tensor(np.log(self.data), represent)\n",
    "        operation =  ('log', self.id)\n",
    "        self.update_s(self.id, new_var.id, operation)\n",
    "        tensor.adj[self.id]['diff'].append(1/(tensor.adj[self.id]['represent']))\n",
    "        return new_var\n",
    "    \n",
    "    def maximum(self, other):\n",
    "        if isinstance(other, tensor):\n",
    "            represent = np.maximum(tensor.adj[self.id]['represent'], tenor.adj[other.id]['represent'])\n",
    "            new_var = tensor(np.maximum(self.data, other.data), represent)\n",
    "            operation = ('maximum', self.id, other.id)\n",
    "            self.update_so(self.id, other.id, new_var.id, operation)\n",
    "            diff_self = (represent == tensnor.adj[self.id]['represent'])\n",
    "            diff_other = (represent == tensor.adj[other.id]['represent'])\n",
    "            tensor.adj[self.id]['diff'].append(diff_self)\n",
    "            tensor.adj[other.id]['diff'].append(diff_other)\n",
    "        else:\n",
    "            represent = np.maximum(tensor.adj[self.id]['represent'], other)\n",
    "            new_var = tensor(np.maximum(self.data, other), represent)\n",
    "            operation = ('maximum', self.id, str(other))\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            diff_self = (represent == tensor.adj[self.id]['represent'])\n",
    "            tensor.adj[self.id]['diff'].append(diff_self)\n",
    "        return new_var\n",
    "    \n",
    "    def minimum(self, other):\n",
    "        if isinstance(other, tensor):\n",
    "            represent = np.minimum(tensor.adj[self.id]['represent'], tenor.adj[other.id]['represent'])\n",
    "            new_var = tensor(np.minimum(self.data, other.data), represent)\n",
    "            operation = ('minimum', self.id, other.id)\n",
    "            self.update_so(self.id, other.id, new_var.id, operation)\n",
    "            diff_self = (represent == tensnor.adj[self.id]['represent'])\n",
    "            diff_other = (represent == tensor.adj[other.id]['represent'])\n",
    "            tensor.adj[self.id]['diff'].append(diff_self)\n",
    "            tensor.adj[other.id]['diff'].append(diff_other)\n",
    "        else:\n",
    "            represent = np.minimum(tensor.adj[self.id]['represent'], other)\n",
    "            new_var = tensor(np.minimum(self.data, other), represent)\n",
    "            operation = ('minimum', self.id, str(other))\n",
    "            self.update_s(self.id, new_var.id, operation)\n",
    "            diff_self = (represent == tensor.adj[self.id]['represent'])\n",
    "            tensor.adj[self.id]['diff'].append(diff_self)\n",
    "        return new_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class torch(tensor):\n",
    "    e = 2.718281828459045\n",
    "    n_samples = 'wait for assigned'\n",
    "    \n",
    "    def __init__(self, data, torch_type='sample', assigned=False):\n",
    "        self.data = data\n",
    "        self.torch_type = torch_type\n",
    "        if assigned == True:\n",
    "            if torch_type == 'sample':\n",
    "                self.rep = self.ele_to_tensor(data, torch_type)\n",
    "                if torch.n_samples == 'wait for assigned':\n",
    "                    torch.n_samples = data.shape[0]\n",
    "            elif torch_type == 'weight':\n",
    "                self.rep = self.ele_to_tensor(data, torch_type)\n",
    "            elif torch_type == 'bias':\n",
    "                self.rep = self.ele_to_tensor(data, torch_type)\n",
    "        else:\n",
    "            self.rep = 'wait for assigned'\n",
    "\n",
    "    def ele_to_tensor(self, matrix, torch_type):\n",
    "        if torch_type == 'sample':\n",
    "            sample_matrix = matrix[:1, :]\n",
    "            o_matrix = np.array(sample_matrix, dtype='object')\n",
    "        elif torch_type != 'sample':\n",
    "            o_matrix = np.array(matrix, dtype='object')\n",
    "        n_rows, n_cols = o_matrix.shape\n",
    "        for r in range(n_rows):\n",
    "            for c in range(n_cols):\n",
    "                if torch_type == 'sample':\n",
    "                    o_matrix[r,c] = tensor(o_matrix[r,c], matrix[:,c:c+1], torch_type)\n",
    "                elif torch_type != 'sample':\n",
    "                    o_matrix[r,c] = tensor(o_matrix[r,c], \n",
    "                                    o_matrix[r,c]*np.ones([torch.n_samples, 1]), torch_type)\n",
    "        return o_matrix\n",
    "    \n",
    "    @classmethod\n",
    "    def ele_to_numeric(self, matrix):\n",
    "        matrix = np.array(matrix, dtype='object')\n",
    "        n_rows, n_cols = matrix.shape\n",
    "        for r in range(n_rows):\n",
    "            for c in range(n_cols):\n",
    "                matrix[r,c] = matrix[r,c].data\n",
    "        return matrix\n",
    "    \n",
    "    @classmethod\n",
    "    def clear_adj(self):\n",
    "        tensor.adj = []\n",
    "        tensor.total_id = 0\n",
    "        tensor.n_samples = 'wait for assigned'\n",
    "        torch.n_samples = 'wait for assigned'\n",
    "            \n",
    "    def dot(self, other):\n",
    "        if isinstance(other, tensor):\n",
    "            new_var = torch(np.dot(self.data, other.data))\n",
    "            new_var.rep = np.dot(self.rep, other.rep)\n",
    "        else:\n",
    "            new_var = torch(np.dot(self.data, other))\n",
    "            new_var.rep = np.dot(self.rep, other)\n",
    "        return new_var\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, torch):\n",
    "            new_var = torch(self.data + other.data)\n",
    "            new_var.rep = self.rep + other.rep\n",
    "        else:\n",
    "            new_var = torch(self.data + other)\n",
    "            new_var.rep = self.rep + other\n",
    "        return new_var\n",
    "    \n",
    "    def __radd__(self, other):\n",
    "        if not isinstance(other, torch):\n",
    "            new_var = torch(other + self.data)\n",
    "            new_var.rep = other + self.rep\n",
    "        return new_var\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, torch):\n",
    "            new_var = torch(self.data - other.data)\n",
    "            new_var.rep = self.rep - other.rep\n",
    "        else:\n",
    "            new_var = torch(self.data - other)\n",
    "            new_var.rep = self.rep - other\n",
    "        return new_var\n",
    "            \n",
    "    def __rsub__(self, other):\n",
    "        if not isinstance(other, torch):\n",
    "            new_var = torch(other - self.data)\n",
    "            new_var.rep = other - self.rep\n",
    "        return new_var\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, torch):\n",
    "            new_var = torch(self.data * other.data)\n",
    "            new_var.rep = self.rep * other.rep\n",
    "        else:\n",
    "            new_var = torch(self.data * other)\n",
    "            new_var.rep = self.rep * other\n",
    "        return new_var\n",
    "    \n",
    "    def __rmul__(self, other):\n",
    "        if not isinstance(other, torch):\n",
    "            new_var = torch(other * self.data)\n",
    "            new_var.rep = other * self.rep\n",
    "        return new_var\n",
    "    \n",
    "    def __truediv__(self, other):\n",
    "        if isinstance(other, torch):\n",
    "            new_var = torch(self.data / other.data)\n",
    "            new_var.rep = self.rep / other.rep\n",
    "        else:\n",
    "            new_var = torch(self.data / other)\n",
    "            new_var.rep = self.rep / other\n",
    "        return new_var\n",
    "        \n",
    "    def __rtruediv__(self, other):\n",
    "        if not isinstance(other, torch):\n",
    "            new_var = torch(other / self.data)\n",
    "            new_var.rep = other / self.rep\n",
    "        return new_var\n",
    "    \n",
    "    def __pow__(self, other):\n",
    "        if isinstance(other, torch):\n",
    "            new_var = torch(self.data ** other.data)\n",
    "            new_var.rep = self.rep ** other.rep\n",
    "        else:\n",
    "            new_var = torch(self.data ** other)\n",
    "            new_var.rep = self.rep ** other\n",
    "        return new_var\n",
    "    \n",
    "    def __rpow__(self, other):\n",
    "        if not isinstance(other, torch):\n",
    "            new_var = torch(other ** self.data)\n",
    "            new_var.rep = other ** self.rep\n",
    "        return new_var\n",
    "    \n",
    "    def __neg__(self):\n",
    "        new_var = torch(-self.data)\n",
    "        new_var.rep = -self.rep\n",
    "        return new_var\n",
    "    \n",
    "    def abs(self):\n",
    "        new_var = torch(np.abs(self.data))\n",
    "        new_var.rep = np.abs(self.rep)\n",
    "        return new_var\n",
    "    \n",
    "    def log(self):\n",
    "        new_var = torch(np.log(self.data))\n",
    "        new_var.rep = np.log(self.rep)\n",
    "        return new_var\n",
    "\n",
    "    def maximum(self, other):\n",
    "        if isinstance(self, torch):\n",
    "            if isinstance(other, torch):\n",
    "                new_var = torch(np.maximum(self.data, other.data))\n",
    "                n_rows, n_cols = self.rep.shape\n",
    "                max_matrix = np.zeros([n_rows, n_cols], dtype='object')\n",
    "                for r in range(n_rows):\n",
    "                    for c in range(n_cols):\n",
    "                        max_tensor = tensor.maximum(self.rep[r,c], other.rep[r,c])\n",
    "                        max_matrix[r,c] = max_tensor\n",
    "                new_var.rep = max_matrix\n",
    "            else:\n",
    "                new_var = torch(np.maximum(self.data, other))\n",
    "                n_rows, n_cols = self.rep.shape\n",
    "                max_matrix = np.zeros([n_rows, n_cols], dtype='object')\n",
    "                for r in range(n_rows):\n",
    "                    for c in range(n_cols):\n",
    "                        max_tensor = tensor.maximum(self.rep[r,c], other)\n",
    "                        max_matrix[r,c] = max_tensor\n",
    "                new_var.rep = max_matrix\n",
    "        else:\n",
    "            if isinstance(other, torch):\n",
    "                new_var = torch(np.maximum(self, other.data))\n",
    "                n_rows, n_cols = other.rep.shape\n",
    "                max_matrix = np.zeros([n_rows, n_cols], dtype='object')\n",
    "                for r in range(n_rows):\n",
    "                    for c in range(n_cols):\n",
    "                        max_tensor = tensor.maximum(other.rep[r,c], self)\n",
    "                        max_matrix[r,c] = max_tensor\n",
    "                new_var.rep = max_matrix\n",
    "            else:\n",
    "                new_var = torch(np.maximum(self, other))\n",
    "        return new_var\n",
    "    \n",
    "    def minimum(self, other):\n",
    "        if isinstance(self, torch):\n",
    "            if isinstance(other, torch):\n",
    "                new_var = torch(np.minimum(self.data, other.data))\n",
    "                n_rows, n_cols = self.rep.shape\n",
    "                min_matrix = np.zeros([n_rows, n_cols], dtype='object')\n",
    "                for r in range(n_rows):\n",
    "                    for c in range(n_cols):\n",
    "                        min_tensor = tensor.minimum(self.rep[r,c], other.rep[r,c])\n",
    "                        min_matrix[r,c] = min_tensor\n",
    "                new_var.rep = min_matrix\n",
    "            else:\n",
    "                new_var = torch(np.minimum(self.data, other))\n",
    "                n_rows, n_cols = self.rep.shape\n",
    "                min_matrix = np.zeros([n_rows, n_cols], dtype='object')\n",
    "                for r in range(n_rows):\n",
    "                    for c in range(n_cols):\n",
    "                        min_tensor = tensor.minimum(self.rep[r,c], other)\n",
    "                        min_matrix[r,c] = min_tensor\n",
    "                new_var.rep = min_matrix\n",
    "        else:\n",
    "            if isinstance(other, torch):\n",
    "                new_var = torch(np.minimum(self, other.data))\n",
    "                n_rows, n_cols = other.rep.shape\n",
    "                min_matrix = np.zeros([n_rows, n_cols], dtype='object')\n",
    "                for r in range(n_rows):\n",
    "                    for c in range(n_cols):\n",
    "                        min_tensor = tensor.minimum(other.rep[r,c], self)\n",
    "                        min_matrix[r,c] = min_tensor\n",
    "                new_var.rep = min_matrix\n",
    "            else:\n",
    "                new_var = torch(np.maximum(self, other))\n",
    "        return new_var\n",
    "\n",
    "    def relu(self):\n",
    "        relu = torch.maximum(self, 0)\n",
    "        return relu\n",
    "    \n",
    "    def prelu(self, alpha):\n",
    "        prelu = torch.maximum(self, 0) + alpha*torch.minimum(self, 0)\n",
    "        return prelu\n",
    "    \n",
    "    def sigmoid(self):\n",
    "        sigmoid = 1/(1 + torch.e**(-self))\n",
    "        return sigmoid\n",
    "    \n",
    "    def tanh(self):\n",
    "        tanh = (torch.e**self - torch.e**(-self))/(torch.e**self + torch.e**(-self))\n",
    "        return tanh\n",
    "    \n",
    "    def softmax(self):\n",
    "        eZ = torch.e**self\n",
    "        denominator = torch.col_sum(eZ)\n",
    "        softmax = eZ/denominator\n",
    "        return softmax\n",
    "    \n",
    "    def col_sum(self):\n",
    "        new_var = torch(np.sum(self.data, axis=1, keepdims=True))\n",
    "        new_var.rep = np.sum(self.rep, axis=1, keepdims=True)\n",
    "        return new_var\n",
    "    \n",
    "    def sum(self):\n",
    "        new_var = torch(np.sum(self.data))\n",
    "        new_var.rep = np.sum(self.rep)\n",
    "        return new_var\n",
    "    \n",
    "    def mean(self):\n",
    "        new_var = torch(np.mean(self.data))\n",
    "        # new_var.rep = np.mean(self.rep)\n",
    "        new_var.rep = self.rep/tensor.n_samples\n",
    "        return new_var\n",
    "    \n",
    "    def sse(self, other):\n",
    "        error = (self - other)**2\n",
    "        sse = torch.sum(error)\n",
    "        return sse\n",
    "    \n",
    "    def mse(self, other):\n",
    "        error = (self - other)**2\n",
    "        mse = torch.mean(error)\n",
    "        return mse\n",
    "    \n",
    "    def m2_entropy(self, other):\n",
    "        error = -(self*np.log(other+np.finfo(np.float32).eps) + (1-self)*np.log(1-other+np.finfo(np.float32).eps))\n",
    "        entropy = torch.mean(error)\n",
    "        return entropy\n",
    "    \n",
    "    def m_entropy(self, other):\n",
    "        error = self*np.log(other+np.finfo(np.float32).eps)\n",
    "        entropy = torch.mean(error)\n",
    "        return entropy\n",
    "    \n",
    "    @classmethod\n",
    "    def forward_diff(self, y_id, x_id):\n",
    "        if (x_id in tensor.adj[y_id]['family']) or (x_id == y_id):\n",
    "            if tensor.adj[x_id]['storage_chain_rule'] is not None:\n",
    "                return tensor.adj[x_id]['storage_chain_rule']\n",
    "            else:\n",
    "                send_to = tensor.adj[x_id]['send_to']\n",
    "                n_send = len(send_to)\n",
    "                if n_send == 1:\n",
    "                    target_id = send_to[0]\n",
    "                    dy_dx = tensor.adj[x_id]['diff'][0] * self.forward_diff(y_id, target_id)\n",
    "                    tensor.adj[x_id]['storage_chain_rule'] = dy_dx\n",
    "                    return dy_dx\n",
    "                elif n_send > 1:\n",
    "                    dy_dx = 0\n",
    "                    for i in range(n_send):\n",
    "                        target_id = send_to[i]\n",
    "                        dy_dx += tensor.adj[x_id]['diff'][i] * self.forward_diff(y_id, target_id)\n",
    "                    tensor.adj[x_id]['storage_chain_rule'] = dy_dx\n",
    "                    return dy_dx\n",
    "                elif n_send == 0:\n",
    "                    return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def gradient(self):\n",
    "        n_rows, n_cols = self.rep.shape\n",
    "        diff_matrix = np.zeros([n_rows, n_cols])\n",
    "        for r in range(n_rows):\n",
    "            for c in range(n_cols):\n",
    "                diff_matrix[r,c] = np.sum(torch.forward_diff(tensor.adj[-1]['id'], self.rep[r,c].id))\n",
    "        return diff_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Data & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trend prediction.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-19888fdca6ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trend prediction.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'E:O'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, parse_cols, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, verbose, parse_dates, date_parser, thousands, comment, skip_footer, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     return io.parse(\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, engine)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_stringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trend prediction.xlsx'"
     ]
    }
   ],
   "source": [
    "Data = pd.read_excel('trend prediction.xlsx', usecols = 'E:O', skiprows = range(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 change dataframe to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataMatrix = Data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(DataMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 split matrix to X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = DataMatrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = DataMatrix.shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = DataMatrix[:, :D]\n",
    "Y = DataMatrix[:, D:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 split data to training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = int(0.8*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X[start:end, :], dtype='float32')\n",
    "Y_train = np.array(Y[start:end, :], dtype='float32')\n",
    "\n",
    "X_test = np.array(X[end:, :], dtype='float32')\n",
    "Y_test = np.array(Y[end:, :], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 normalize X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_X = ai.Normalize(X_train, norm_type='minmaxNorm')\n",
    "norm_Y = ai.Normalize(Y_train, norm_type='minmaxNorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = norm_X.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = norm_X.fit(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_hidden1 = 10\n",
    "node_hidden2 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.random.randn(D, node_hidden1)/np.sqrt(node_hidden1)\n",
    "B1 = np.random.randn(1, node_hidden1)/np.sqrt(node_hidden1)\n",
    "W2 = np.random.randn(node_hidden1, node_hidden2)/np.sqrt(node_hidden2)\n",
    "B2 = np.random.randn(1, node_hidden2)/np.sqrt(node_hidden2)\n",
    "W3 = np.random.randn(node_hidden2, 1)\n",
    "B3 = np.random.randn(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 200\n",
    "lr = 0.1\n",
    "loss_list = []\n",
    "for i in range(epoch):\n",
    "    t_X0 = torch(X_train_norm, torch_type='sample', assigned=True)\n",
    "    t_Y = torch(Y_train, torch_type='sample', assigned=True)\n",
    "    t_W1 = torch(W1, torch_type='weight', assigned=True)\n",
    "    t_B1 = torch(B1, torch_type='bias', assigned=True)\n",
    "    t_W2 = torch(W2, torch_type='weight', assigned=True)\n",
    "    t_B2 = torch(B2, torch_type='bias', assigned=True)\n",
    "    t_W3 = torch(W3, torch_type='weight', assigned=True)\n",
    "    t_B3 = torch(B3, torch_type='bias', assigned=True)\n",
    "    \n",
    "    t_Z1 = torch.dot(t_X0, t_W1) + t_B1\n",
    "    t_X1 = torch.prelu(t_Z1, 0.5)\n",
    "    t_Z2 = torch.dot(t_X1, t_W2) + t_B2\n",
    "    t_X2 = torch.prelu(t_Z2, 0.5)\n",
    "    t_Z3 = torch.dot(t_X2, t_W3) + t_B3\n",
    "    t_X3 = torch.sigmoid(t_Z3)\n",
    "    \n",
    "    loss = torch.m2_entropy(t_Y, t_X3)\n",
    "    loss_list.append(loss.data)\n",
    "    \n",
    "    dW3 = torch.gradient(t_W3)\n",
    "    dB3 = torch.gradient(t_B3)\n",
    "    dW2 = torch.gradient(t_W2)\n",
    "    dB2 = torch.gradient(t_B2)\n",
    "    dW1 = torch.gradient(t_W1)\n",
    "    dB1 = torch.gradient(t_B1)\n",
    "    \n",
    "    W3 -= lr*dW3\n",
    "    B3 -= lr*dB3\n",
    "    W2 -= lr*dW2\n",
    "    B2 -= lr*dB2\n",
    "    W1 -= lr*dW1\n",
    "    B1 -= lr*dB1\n",
    "    \n",
    "    torch.clear_adj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.ErrorScore.find_error(Y_train, t_X3.data, 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_X0 = torch(X_test_norm, torch_type='sample', assigned=True)\n",
    "t_W1 = torch(W1, torch_type='weight', assigned=True)\n",
    "t_B1 = torch(B1, torch_type='bias', assigned=True)\n",
    "t_W2 = torch(W2, torch_type='weight', assigned=True)\n",
    "t_B2 = torch(B2, torch_type='bias', assigned=True)\n",
    "t_W3 = torch(W3, torch_type='weight', assigned=True)\n",
    "t_B3 = torch(B3, torch_type='bias', assigned=True)\n",
    "\n",
    "t_Z1 = torch.dot(t_X0, t_W1) + t_B1\n",
    "t_X1 = torch.prelu(t_Z1, 0.5)\n",
    "t_Z2 = torch.dot(t_X1, t_W2) + t_B2\n",
    "t_X2 = torch.prelu(t_Z2, 0.5)\n",
    "t_Z3 = torch.dot(t_X2, t_W3) + t_B3\n",
    "t_X3 = torch.sigmoid(t_Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.ErrorScore.find_error(Y_test, t_X3.data, 'binary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
